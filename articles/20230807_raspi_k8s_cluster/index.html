<!doctype html><html lang=ja dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Raspberry Pi 4 Model B でKubernetes cluster構築した | /home/lunarxlark/.config/blog</title><meta name=keywords content="kubernetes,raspberry-pi"><meta name=description content="完成形です。いぇい。


材料

  
      
          材料
          個数
      
  
  
      
          Raspberry Pi 4 Model B 8GB
          4
      
      
          PoE HAT(E)
          4
      
      
          PoE対応 スイッチングハブ
          1
      
      
          無線ルーター
          1
      
      
          MicroSD 128GB
          4
      
      
          LAN (0.15m)
          4
      
      
          LAN (0.3m)
          1
      
      
          ケース
          1
      
      
          追加スペーサー
          50個入り
      
  


組み立ての感想
見た目をスッキリさせたかったので、ラズパイの電源は PoE HATによりハブからLANで取ってます。
ただ、これだとLANを引っこ抜いてノードを切り離すことが出来ないので失敗したかなって思ってます。
LAN引っこ抜いてノードネットワーク障害ごっこしたいのに、電源も落ちちゃう。
cf. PoE (Power Over Ethernet)。
また、ケースでもPoE HATで失敗しました。
PoE HATを付けると高さが高くなります。(値段も)
買ったケースのファンとPoE HATのIsolation Transformerがぶつかります。
なので、ケース付属スペーサーだけでは足りないのでスペーサーを買い足しました。
(そして、そのスペーサーが付属スペーサーのネジ径と合わない&mldr;。付属のはM2だったっぽい&mldr;。)
付属スペーサーは高さ20mm。このケース(+ファン) + PoE HAT の場合、30mmでぴったり合います。
Amazonで激安のPoE HATはさらに高くなるので、ご注意を。

k8s cluster 構築
0. 別PCでの準備

無線ルーターを中継機として既存LANに参加させます。
Raspberry Pi Imagerを使ってmicroSDカード4枚にRaspberry Pi OS(64-bit) Liteを書き込みます。

Imagerでホスト名やssh有効化、user/passwd設定等出来るのでここでやっても可。



中継機が192.168.8.1なので、192.168.8.xで4台に固定IPを割り当てていきます。"><meta name=author content><link rel=canonical href=https://lunarxlark.github.io/articles/20230807_raspi_k8s_cluster/><link crossorigin=anonymous href=/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn+yY=" rel="preload stylesheet" as=style><link rel=icon href=https://lunarxlark.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lunarxlark.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lunarxlark.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://lunarxlark.github.io/apple-touch-icon.png><link rel=mask-icon href=https://lunarxlark.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ja href=https://lunarxlark.github.io/articles/20230807_raspi_k8s_cluster/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-HC9218ZECN"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-HC9218ZECN")}</script><meta property="og:url" content="https://lunarxlark.github.io/articles/20230807_raspi_k8s_cluster/"><meta property="og:site_name" content="/home/lunarxlark/.config/blog"><meta property="og:title" content="Raspberry Pi 4 Model B でKubernetes cluster構築した"><meta property="og:description" content="完成形です。いぇい。 材料 材料 個数 Raspberry Pi 4 Model B 8GB 4 PoE HAT(E) 4 PoE対応 スイッチングハブ 1 無線ルーター 1 MicroSD 128GB 4 LAN (0.15m) 4 LAN (0.3m) 1 ケース 1 追加スペーサー 50個入り 組み立ての感想 見た目をスッキリさせたかったので、ラズパイの電源は PoE HATによりハブからLANで取ってます。
ただ、これだとLANを引っこ抜いてノードを切り離すことが出来ないので失敗したかなって思ってます。
LAN引っこ抜いてノードネットワーク障害ごっこしたいのに、電源も落ちちゃう。
cf. PoE (Power Over Ethernet)。
また、ケースでもPoE HATで失敗しました。
PoE HATを付けると高さが高くなります。(値段も)
買ったケースのファンとPoE HATのIsolation Transformerがぶつかります。
なので、ケース付属スペーサーだけでは足りないのでスペーサーを買い足しました。
(そして、そのスペーサーが付属スペーサーのネジ径と合わない…。付属のはM2だったっぽい…。)
付属スペーサーは高さ20mm。このケース(+ファン) + PoE HAT の場合、30mmでぴったり合います。
Amazonで激安のPoE HATはさらに高くなるので、ご注意を。
k8s cluster 構築 0. 別PCでの準備 無線ルーターを中継機として既存LANに参加させます。 Raspberry Pi Imagerを使ってmicroSDカード4枚にRaspberry Pi OS(64-bit) Liteを書き込みます。 Imagerでホスト名やssh有効化、user/passwd設定等出来るのでここでやっても可。 中継機が192.168.8.1なので、192.168.8.xで4台に固定IPを割り当てていきます。"><meta property="og:locale" content="ja"><meta property="og:type" content="article"><meta property="article:section" content="articles"><meta property="article:published_time" content="2023-08-07T00:00:00+00:00"><meta property="article:modified_time" content="2023-08-07T00:00:00+00:00"><meta property="article:tag" content="Kubernetes"><meta property="article:tag" content="Raspberry-Pi"><meta name=twitter:card content="summary"><meta name=twitter:title content="Raspberry Pi 4 Model B でKubernetes cluster構築した"><meta name=twitter:description content="完成形です。いぇい。


材料

  
      
          材料
          個数
      
  
  
      
          Raspberry Pi 4 Model B 8GB
          4
      
      
          PoE HAT(E)
          4
      
      
          PoE対応 スイッチングハブ
          1
      
      
          無線ルーター
          1
      
      
          MicroSD 128GB
          4
      
      
          LAN (0.15m)
          4
      
      
          LAN (0.3m)
          1
      
      
          ケース
          1
      
      
          追加スペーサー
          50個入り
      
  


組み立ての感想
見た目をスッキリさせたかったので、ラズパイの電源は PoE HATによりハブからLANで取ってます。
ただ、これだとLANを引っこ抜いてノードを切り離すことが出来ないので失敗したかなって思ってます。
LAN引っこ抜いてノードネットワーク障害ごっこしたいのに、電源も落ちちゃう。
cf. PoE (Power Over Ethernet)。
また、ケースでもPoE HATで失敗しました。
PoE HATを付けると高さが高くなります。(値段も)
買ったケースのファンとPoE HATのIsolation Transformerがぶつかります。
なので、ケース付属スペーサーだけでは足りないのでスペーサーを買い足しました。
(そして、そのスペーサーが付属スペーサーのネジ径と合わない&mldr;。付属のはM2だったっぽい&mldr;。)
付属スペーサーは高さ20mm。このケース(+ファン) + PoE HAT の場合、30mmでぴったり合います。
Amazonで激安のPoE HATはさらに高くなるので、ご注意を。

k8s cluster 構築
0. 別PCでの準備

無線ルーターを中継機として既存LANに参加させます。
Raspberry Pi Imagerを使ってmicroSDカード4枚にRaspberry Pi OS(64-bit) Liteを書き込みます。

Imagerでホスト名やssh有効化、user/passwd設定等出来るのでここでやっても可。



中継機が192.168.8.1なので、192.168.8.xで4台に固定IPを割り当てていきます。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Articles","item":"https://lunarxlark.github.io/articles/"},{"@type":"ListItem","position":2,"name":"Raspberry Pi 4 Model B でKubernetes cluster構築した","item":"https://lunarxlark.github.io/articles/20230807_raspi_k8s_cluster/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Raspberry Pi 4 Model B でKubernetes cluster構築した","name":"Raspberry Pi 4 Model B でKubernetes cluster構築した","description":"完成形です。いぇい。 材料 材料 個数 Raspberry Pi 4 Model B 8GB 4 PoE HAT(E) 4 PoE対応 スイッチングハブ 1 無線ルーター 1 MicroSD 128GB 4 LAN (0.15m) 4 LAN (0.3m) 1 ケース 1 追加スペーサー 50個入り 組み立ての感想 見た目をスッキリさせたかったので、ラズパイの電源は PoE HATによりハブからLANで取ってます。\nただ、これだとLANを引っこ抜いてノードを切り離すことが出来ないので失敗したかなって思ってます。\nLAN引っこ抜いてノードネットワーク障害ごっこしたいのに、電源も落ちちゃう。\ncf. PoE (Power Over Ethernet)。\nまた、ケースでもPoE HATで失敗しました。\nPoE HATを付けると高さが高くなります。(値段も)\n買ったケースのファンとPoE HATのIsolation Transformerがぶつかります。\nなので、ケース付属スペーサーだけでは足りないのでスペーサーを買い足しました。\n(そして、そのスペーサーが付属スペーサーのネジ径と合わない\u0026hellip;。付属のはM2だったっぽい\u0026hellip;。)\n付属スペーサーは高さ20mm。このケース(+ファン) + PoE HAT の場合、30mmでぴったり合います。\nAmazonで激安のPoE HATはさらに高くなるので、ご注意を。\nk8s cluster 構築 0. 別PCでの準備 無線ルーターを中継機として既存LANに参加させます。 Raspberry Pi Imagerを使ってmicroSDカード4枚にRaspberry Pi OS(64-bit) Liteを書き込みます。 Imagerでホスト名やssh有効化、user/passwd設定等出来るのでここでやっても可。 中継機が192.168.8.1なので、192.168.8.xで4台に固定IPを割り当てていきます。\n","keywords":["kubernetes","raspberry-pi"],"articleBody":"完成形です。いぇい。 材料 材料 個数 Raspberry Pi 4 Model B 8GB 4 PoE HAT(E) 4 PoE対応 スイッチングハブ 1 無線ルーター 1 MicroSD 128GB 4 LAN (0.15m) 4 LAN (0.3m) 1 ケース 1 追加スペーサー 50個入り 組み立ての感想 見た目をスッキリさせたかったので、ラズパイの電源は PoE HATによりハブからLANで取ってます。\nただ、これだとLANを引っこ抜いてノードを切り離すことが出来ないので失敗したかなって思ってます。\nLAN引っこ抜いてノードネットワーク障害ごっこしたいのに、電源も落ちちゃう。\ncf. PoE (Power Over Ethernet)。\nまた、ケースでもPoE HATで失敗しました。\nPoE HATを付けると高さが高くなります。(値段も)\n買ったケースのファンとPoE HATのIsolation Transformerがぶつかります。\nなので、ケース付属スペーサーだけでは足りないのでスペーサーを買い足しました。\n(そして、そのスペーサーが付属スペーサーのネジ径と合わない…。付属のはM2だったっぽい…。)\n付属スペーサーは高さ20mm。このケース(+ファン) + PoE HAT の場合、30mmでぴったり合います。\nAmazonで激安のPoE HATはさらに高くなるので、ご注意を。\nk8s cluster 構築 0. 別PCでの準備 無線ルーターを中継機として既存LANに参加させます。 Raspberry Pi Imagerを使ってmicroSDカード4枚にRaspberry Pi OS(64-bit) Liteを書き込みます。 Imagerでホスト名やssh有効化、user/passwd設定等出来るのでここでやっても可。 中継機が192.168.8.1なので、192.168.8.xで4台に固定IPを割り当てていきます。\n192.168.8.101 … rp1 コントロールプレーン 192.168.8.102 … rp2 ワーカーノード 192.168.8.103 … rp3 ワーカーノード 192.168.8.104 … rp4 ワーカーノード 1. ホスト名設定 $ sudo vi /etc/hostname rpx # \u003c- xには識別番号 $ sudo vi /etc/hosts ... 127.0.0.1 rpx 192.168.8.101 rp1 # \u003c- あとでIPアドレスを固定 192.168.8.102 rp2 192.168.8.103 rp3 192.168.8.104 rp4 $ reboot 2. インターネット接続 \u0026 timezone $ sudo raspi-config 1 System Options \u003e S1 Wireless LAN\nJP を選択 SSIDを入力 アクセスポイントのパスワードを入力 5 localisation options \u003e L2 Timezone \u003e Asia \u003e Tokyoを選択 WLANで一度国を選択すると次から国の選択が出てきませんでした。\n後述するファイルに国コード contry を JP に修正することで対応出来ます。\n3. Tailscale Install with one commandからインストールします。\n$ curl -fsSL https://tailscale.com/install.sh | sh ... Installation complete! log in to start using Tailscale by running: sudo tailscale up $ sudo tailscale up --ssh # \u003c-- tailscale sshを有効に。 to Authenticate, visit: https://login.tailscale.com/a/xxxxxxxx このURLを入れるのが一番しんどかったです。\n(上記URLへアクセスし認証を通せばいいので、写真撮ってOCRからiPhoneでアクセスしました。fが£になるのが辛かった。)\ntailscaleのadminコンソールに表示されるホスト名は、クライアントPC側でホスト名を変更したら更新されます。\nラズパイに設定するホスト名でtailscaleでも管理したいので特に触らない。\nadmin consoleから接続した端末に対して disable key expiry 。\nこれ以降はtailscale ssh で接続して作業します。\n(weztermがpaneのsyncronizeしない/必要に感じてないそうなので、tmuxでやっていきます。)\n4. リポジトリ\u0026パッケージ更新 sudo apt update sudo apt upgrade -y 5. IPアドレス固定 $ sudo vi /etc/dhcpcd.conf ... # Example static IP configuration: interface eth0 static ip_address=192.168.8.10x/24 static routers=192.168.8.1 static domain_name_servers=192.168.8.1 8.8.8.8 ... 6. kubeadmの必要要件を満たす kubeadmのインストールを 始める前にに記載があるので設定する\n6.1. swap無効化 システムに応じたswapの無効化をしてくれよな！って書いてある。 Raspberry Pi OSの場合、/etc/fstabを見ると dphys-swapfile swap[on|off]使ってくれよな！って書いてあった。\n$ sudo swapon # 現状確認 NAME TYPE SIZE USED PRIO /var/swap file 100M. 0B. -2 $ sudo dphys-swapfile swapoff $ sudo systemctl stop dphys-swapfile $ sudo systemctl disable dphys-swapfile # 設定確認 $ sudo swapon $ #設定なし 6.2. cgroupのmemory有効化 $ cat /proc/cgroups # 現状確認 #subsys_name hierarchy num_cgroups enabled cpuset 0 80 1 cpu 0 80 1 cpuacct 0 80 1 blkio 0 80 1 memory 0 80 0 \u003c-- 無効になってる devices 0 80 1 freezer 0 80 1 net_cls 0 80 1 perf_event 0 80 1 net_prio 0 80 1 pids 0 80 1 # 有効化(末尾にcgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memoryを追加) $ sudo sed -i \"s/$/ cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory/\" /boot/firmware/cmdline.txt $ sudo reboot 7. containerd/runc/CNI pluginsのインストール + α コンテナランタイムとしてcontainerdを使用します。\ndocker engineを使用しても引き続きk8sは動くようですが、必要最小限の構成にしたいためです。\nGetting started with containerdに従います。\n7.1. containerd 執筆時点のaptだとv1.4.13が降ってきて、cgroup API v1を使おうとしますが、 他ツールではcgroup API v2を使うバージョンが降ってきます。\n結果、cgroup APIのバージョンが違うじゃねーかってkubeletに怒られるのでここではcontainerdのバージョンを指定できる方法でインストールします。\nGitHub Release: containerd/containerd\n$ # containerdのインストール $ containerd_version=\"1.7.14\" $ curl -fsSL -o /tmp/containerd.tar.gz https://github.com/containerd/containerd/releases/download/v${containerd_version}/containerd-${containerd_version}-linux-arm64.tar.gz $ sudo tar Cxzvf /usr/local /tmp/containerd.tar.gz $ rm /tmp/containerd.tar.gz $ # systemdに登録 $ sudo mkdir -p /usr/local/lib/systemd/system $ sudo curl https://raw.githubusercontent.com/containerd/containerd/main/containerd.service -o /usr/local/lib/systemd/system/containerd.service $ sudo systemctl daemon-reload $ sudo systemctl enable --now containerd 7.2. runc GitHub Release: opencontainers/runc\n$ runc_version=\"1.1.12\" $ curl -fsSL -o /tmp/runc https://github.com/opencontainers/runc/releases/download/v${runc_version}/runc.arm64 $ sudo install -m 755 /tmp/runc /usr/local/sbin/runc $ rm /tmp/runc 7.3. CNI plugins $ cni_plugins_version=\"1.4.0\" $ sudo mkdir -p /opt/cni/bin $ curl -fsSL -o /tmp/cni-plugins.tgz https://github.com/containernetworking/plugins/releases/download/v${cni_plugins_version}/cni-plugins-linux-arm-v${cni_plugins_version}.tgz $ sudo tar Cxzvf /opt/cni/bin /tmp/cni-plugins.tgz $ rm /tmp/cni-plugins.tgz 7.4. IPv4フォワーディングを有効化し、iptablesからブリッジされたトラフィックを見えるようにする こちらの設定に従います。\n(わかってないので後で調べる。)\n$ cat \u003c","wordCount":"1396","inLanguage":"ja","datePublished":"2023-08-07T00:00:00Z","dateModified":"2023-08-07T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://lunarxlark.github.io/articles/20230807_raspi_k8s_cluster/"},"publisher":{"@type":"Organization","name":"/home/lunarxlark/.config/blog","logo":{"@type":"ImageObject","url":"https://lunarxlark.github.io/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://lunarxlark.github.io/ accesskey=h title="/home/lunarxlark/.config/blog (Alt + H)">/home/lunarxlark/.config/blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://lunarxlark.github.io/ title=Home><span>Home</span></a></li><li><a href=https://lunarxlark.github.io/about title=About><span>About</span></a></li><li><a href=https://lunarxlark.github.io/tags title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Raspberry Pi 4 Model B でKubernetes cluster構築した</h1><div class=post-meta><span title='2023-08-07 00:00:00 +0000 UTC'>2023年8月7日</span>&nbsp;·&nbsp;<span>7 分</span></div></header><div class=post-content><p>完成形です。いぇい。
<img alt=完成形 loading=lazy src=/images/rpi_cluster.jpg></p><hr><h2 id=材料>材料<a hidden class=anchor aria-hidden=true href=#材料>#</a></h2><table><thead><tr><th>材料</th><th>個数</th></tr></thead><tbody><tr><td><a href=https://www.switch-science.com/products/6370>Raspberry Pi 4 Model B 8GB</a></td><td>4</td></tr><tr><td><a href=https://www.switch-science.com/products/8726>PoE HAT(E)</a></td><td>4</td></tr><tr><td><a href="https://www.amazon.co.jp/gp/product/B0763TGBTS/ref=ppx_yo_dt_b_asin_title_o08_s00?ie=UTF8&amp;psc=1">PoE対応 スイッチングハブ</a></td><td>1</td></tr><tr><td><a href="https://www.amazon.co.jp/gp/product/B0B4S2V99D/ref=ppx_yo_dt_b_asin_title_o07_s00?ie=UTF8&amp;psc=1">無線ルーター</a></td><td>1</td></tr><tr><td>MicroSD 128GB</td><td>4</td></tr><tr><td>LAN (0.15m)</td><td>4</td></tr><tr><td>LAN (0.3m)</td><td>1</td></tr><tr><td><a href="https://www.amazon.co.jp/gp/product/B07TJ15YL1/ref=ppx_yo_dt_b_asin_title_o07_s01?ie=UTF8&amp;th=1">ケース</a></td><td>1</td></tr><tr><td><a href="https://www.amazon.co.jp/gp/product/B08FT76RFX/ref=ppx_yo_dt_b_asin_title_o03_s00?ie=UTF8&amp;psc=1">追加スペーサー</a></td><td>50個入り</td></tr></tbody></table><hr><h2 id=組み立ての感想>組み立ての感想<a hidden class=anchor aria-hidden=true href=#組み立ての感想>#</a></h2><p>見た目をスッキリさせたかったので、ラズパイの電源は PoE HATによりハブからLANで取ってます。<br>ただ、これだとLANを引っこ抜いてノードを切り離すことが出来ないので失敗したかなって思ってます。<br>LAN引っこ抜いてノードネットワーク障害ごっこしたいのに、電源も落ちちゃう。<br>cf. <a href=https://ja.wikipedia.org/wiki/Power_over_Ethernet>PoE (Power Over Ethernet)</a>。</p><p>また、ケースでもPoE HATで失敗しました。<br>PoE HATを付けると高さが高くなります。(値段も)<br>買ったケースのファンとPoE HATのIsolation Transformerがぶつかります。<br>なので、ケース付属スペーサーだけでは足りないのでスペーサーを買い足しました。<br>(そして、そのスペーサーが付属スペーサーのネジ径と合わない&mldr;。付属のはM2だったっぽい&mldr;。)<br>付属スペーサーは高さ20mm。このケース(+ファン) + PoE HAT の場合、30mmでぴったり合います。<br>Amazonで激安のPoE HATはさらに高くなるので、ご注意を。</p><hr><h2 id=k8s-cluster-構築>k8s cluster 構築<a hidden class=anchor aria-hidden=true href=#k8s-cluster-構築>#</a></h2><h3 id=0-別pcでの準備>0. 別PCでの準備<a hidden class=anchor aria-hidden=true href=#0-別pcでの準備>#</a></h3><ol><li>無線ルーターを中継機として既存LANに参加させます。</li><li>Raspberry Pi Imagerを使ってmicroSDカード4枚にRaspberry Pi OS(64-bit) Liteを書き込みます。<ul><li>Imagerでホスト名やssh有効化、user/passwd設定等出来るのでここでやっても可。</li></ul></li></ol><p>中継機が192.168.8.1なので、192.168.8.xで4台に固定IPを割り当てていきます。</p><ul><li>192.168.8.101 &mldr; rp1 コントロールプレーン</li><li>192.168.8.102 &mldr; rp2 ワーカーノード</li><li>192.168.8.103 &mldr; rp3 ワーカーノード</li><li>192.168.8.104 &mldr; rp4 ワーカーノード</li></ul><hr><h3 id=1-ホスト名設定>1. ホスト名設定<a hidden class=anchor aria-hidden=true href=#1-ホスト名設定>#</a></h3><pre tabindex=0><code>$ sudo vi /etc/hostname
rpx   # &lt;- xには識別番号
</code></pre><pre tabindex=0><code>$ sudo vi /etc/hosts
...
127.0.0.1 rpx

192.168.8.101 rp1 # &lt;- あとでIPアドレスを固定
192.168.8.102 rp2
192.168.8.103 rp3
192.168.8.104 rp4
</code></pre><pre tabindex=0><code>$ reboot
</code></pre><hr><h3 id=2-インターネット接続--timezone>2. インターネット接続 & timezone<a hidden class=anchor aria-hidden=true href=#2-インターネット接続--timezone>#</a></h3><pre tabindex=0><code>$ sudo raspi-config
</code></pre><p><code>1 System Options</code> > <code>S1 Wireless LAN</code></p><ol><li><code>JP</code> を選択</li><li>SSIDを入力</li><li>アクセスポイントのパスワードを入力</li><li><code>5 localisation options</code> > <code>L2 Timezone</code> > <code>Asia</code> > <code>Tokyo</code>を選択</li></ol><blockquote><p>WLANで一度国を選択すると次から国の選択が出てきませんでした。<br>後述するファイルに国コード <code>contry</code> を <code>JP</code> に修正することで対応出来ます。</p></blockquote><hr><h3 id=3-tailscale>3. Tailscale<a hidden class=anchor aria-hidden=true href=#3-tailscale>#</a></h3><p><a href=https://tailscale.com/download/linux>Install with one command</a>からインストールします。</p><pre tabindex=0><code>$ curl -fsSL https://tailscale.com/install.sh | sh
...
Installation complete! log in to start using Tailscale by running:

sudo tailscale up
</code></pre><pre tabindex=0><code>$ sudo tailscale up --ssh # &lt;-- tailscale sshを有効に。

to Authenticate, visit:

    https://login.tailscale.com/a/xxxxxxxx
</code></pre><p>このURLを入れるのが一番しんどかったです。<br>(上記URLへアクセスし認証を通せばいいので、写真撮ってOCRからiPhoneでアクセスしました。fが£になるのが辛かった。)<br>tailscaleのadminコンソールに表示されるホスト名は、クライアントPC側でホスト名を変更したら更新されます。<br>ラズパイに設定するホスト名でtailscaleでも管理したいので特に触らない。</p><p>admin consoleから接続した端末に対して <code>disable key expiry</code> 。<br>これ以降はtailscale ssh で接続して作業します。<br>(weztermがpaneのsyncronizeしない/必要に感じてないそうなので、tmuxでやっていきます。)</p><hr><h3 id=4-リポジトリパッケージ更新>4. リポジトリ&パッケージ更新<a hidden class=anchor aria-hidden=true href=#4-リポジトリパッケージ更新>#</a></h3><pre tabindex=0><code>sudo apt update
sudo apt upgrade -y
</code></pre><hr><h3 id=5-ipアドレス固定>5. IPアドレス固定<a hidden class=anchor aria-hidden=true href=#5-ipアドレス固定>#</a></h3><pre tabindex=0><code>$ sudo vi /etc/dhcpcd.conf
...
# Example static IP configuration:
interface eth0
static ip_address=192.168.8.10x/24
static routers=192.168.8.1
static domain_name_servers=192.168.8.1 8.8.8.8

...
</code></pre><hr><h3 id=6-kubeadmの必要要件を満たす>6. kubeadmの必要要件を満たす<a hidden class=anchor aria-hidden=true href=#6-kubeadmの必要要件を満たす>#</a></h3><p>kubeadmのインストールを <a href=https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/>始める前に</a>に記載があるので設定する</p><h4 id=61-swap無効化>6.1. swap無効化<a hidden class=anchor aria-hidden=true href=#61-swap無効化>#</a></h4><p>システムに応じたswapの無効化をしてくれよな！って書いてある。
Raspberry Pi OSの場合、<code>/etc/fstab</code>を見ると <code>dphys-swapfile swap[on|off]</code>使ってくれよな！って書いてあった。</p><pre tabindex=0><code>$ sudo swapon   # 現状確認
NAME      TYPE SIZE USED PRIO
/var/swap file 100M.  0B.  -2

$ sudo dphys-swapfile swapoff
$ sudo systemctl stop dphys-swapfile
$ sudo systemctl disable dphys-swapfile

# 設定確認
$ sudo swapon
$ #設定なし
</code></pre><h4 id=62-cgroupのmemory有効化>6.2. cgroupのmemory有効化<a hidden class=anchor aria-hidden=true href=#62-cgroupのmemory有効化>#</a></h4><pre tabindex=0><code>$ cat /proc/cgroups   # 現状確認
#subsys_name    hierarchy       num_cgroups     enabled
cpuset  0       80      1
cpu     0       80      1
cpuacct 0       80      1
blkio   0       80      1
memory  0       80      0   &lt;-- 無効になってる
devices 0       80      1
freezer 0       80      1
net_cls 0       80      1
perf_event      0       80      1
net_prio        0       80      1
pids    0       80      1
# 有効化(末尾にcgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memoryを追加)
$ sudo sed -i &#34;s/$/ cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory/&#34; /boot/firmware/cmdline.txt
$ sudo reboot
</code></pre><hr><h3 id=7-containerdrunccni-pluginsのインストール--α>7. containerd/runc/CNI pluginsのインストール + α<a hidden class=anchor aria-hidden=true href=#7-containerdrunccni-pluginsのインストール--α>#</a></h3><p>コンテナランタイムとしてcontainerdを使用します。<br>docker engineを使用しても引き続きk8sは動くようですが、必要最小限の構成にしたいためです。</p><p><a href=https://github.com/containerd/containerd/blob/main/docs/getting-started.md>Getting started with containerd</a>に従います。</p><h4 id=71-containerd>7.1. containerd<a hidden class=anchor aria-hidden=true href=#71-containerd>#</a></h4><p>執筆時点のaptだとv1.4.13が降ってきて、cgroup API v1を使おうとしますが、 他ツールではcgroup API v2を使うバージョンが降ってきます。<br>結果、cgroup APIのバージョンが違うじゃねーかってkubeletに怒られるのでここではcontainerdのバージョンを指定できる方法でインストールします。</p><p><a href=https://github.com/containerd/containerd/releases>GitHub Release: containerd/containerd</a></p><pre tabindex=0><code>$ # containerdのインストール
$ containerd_version=&#34;1.7.14&#34;
$ curl -fsSL -o /tmp/containerd.tar.gz https://github.com/containerd/containerd/releases/download/v${containerd_version}/containerd-${containerd_version}-linux-arm64.tar.gz
$ sudo tar Cxzvf /usr/local /tmp/containerd.tar.gz
$ rm /tmp/containerd.tar.gz
</code></pre><pre tabindex=0><code>$ # systemdに登録
$ sudo mkdir -p /usr/local/lib/systemd/system
$ sudo curl https://raw.githubusercontent.com/containerd/containerd/main/containerd.service -o /usr/local/lib/systemd/system/containerd.service
$ sudo systemctl daemon-reload
$ sudo systemctl enable --now containerd
</code></pre><h4 id=72-runc>7.2. runc<a hidden class=anchor aria-hidden=true href=#72-runc>#</a></h4><p><a href=https://github.com/opencontainers/runc/releases>GitHub Release: opencontainers/runc</a></p><pre tabindex=0><code>$ runc_version=&#34;1.1.12&#34;
$ curl -fsSL -o /tmp/runc https://github.com/opencontainers/runc/releases/download/v${runc_version}/runc.arm64
$ sudo install -m 755 /tmp/runc /usr/local/sbin/runc
$ rm /tmp/runc
</code></pre><h4 id=73-cni-plugins>7.3. CNI plugins<a hidden class=anchor aria-hidden=true href=#73-cni-plugins>#</a></h4><pre tabindex=0><code>$ cni_plugins_version=&#34;1.4.0&#34;
$ sudo mkdir -p /opt/cni/bin
$ curl -fsSL -o /tmp/cni-plugins.tgz https://github.com/containernetworking/plugins/releases/download/v${cni_plugins_version}/cni-plugins-linux-arm-v${cni_plugins_version}.tgz
$ sudo tar Cxzvf /opt/cni/bin /tmp/cni-plugins.tgz
$ rm /tmp/cni-plugins.tgz
</code></pre><h4 id=74-ipv4フォワーディングを有効化しiptablesからブリッジされたトラフィックを見えるようにする>7.4. IPv4フォワーディングを有効化し、iptablesからブリッジされたトラフィックを見えるようにする<a hidden class=anchor aria-hidden=true href=#74-ipv4フォワーディングを有効化しiptablesからブリッジされたトラフィックを見えるようにする>#</a></h4><p><a href=https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/#%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%A8%E8%A8%AD%E5%AE%9A%E3%81%AE%E5%BF%85%E9%A0%88%E8%A6%81%E4%BB%B6>こちらの設定</a>に従います。<br>(わかってないので後で調べる。)</p><pre tabindex=0><code>$ cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

$ sudo modprobe overlay
$ sudo modprobe br_netfilter
# モジュールが読み込まれていることを確認
$ lsmod | grep br_netfilter
$ lsmod | grep overlay
</code></pre><pre tabindex=0><code># この構成に必要なカーネルパラメーター、再起動しても値は永続します
$ cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
EOF

# 再起動せずにカーネルパラメーターを適用
$ sudo sysctl --system

# 各カーネルパラメータがて1に設定されていることを確認
$ sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
</code></pre><h4 id=75-cgroupドライバーにsystemdを設定>7.5. cgroupドライバーにsystemdを設定<a hidden class=anchor aria-hidden=true href=#75-cgroupドライバーにsystemdを設定>#</a></h4><p>初期設定ファイルを出力してsystemdを指定する。
(公式に沿うならファイル開いて場所を確認した方がいい。)</p><pre tabindex=0><code>$ sudo mkdir -p /etc/containerd
$ containerd config default | sed &#34;s/SystemdCgroup = false/SystemdCgroup = true/&#34; | sudo tee /etc/containerd/config.toml
$ sudo systemctl restart containerd
</code></pre><hr><h3 id=8-kubeadm--kubelet--kubectl-のインストール>8. <code>kubeadm</code> / <code>kubelet</code> / <code>kubectl</code> のインストール<a hidden class=anchor aria-hidden=true href=#8-kubeadm--kubelet--kubectl-のインストール>#</a></h3><p><a href=https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#kubeadm-kubelet-kubectl%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB>公式の手順</a>に沿う</p><pre tabindex=0><code># 1. `apt`のパッケージ一覧を更新し、Kubernetesの`apt`リポジトリを利用するのに必要なパッケージをインストールします:
$ sudo apt-get install -y apt-transport-https ca-certificates curl

# 2. Google Cloudの公開鍵をダウンロードします:
# `/etc/apt/keyrings`フォルダーが存在しない場合は、curlコマンドの前に作成する必要があります。下記の備考を参照してください。
# sudo mkdir -p -m 755 /etc/apt/keyrings
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# 3. Kubernetesの`apt`リポジトリを追加します:
echo &#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /&#39; | sudo tee /etc/apt/sources.list.d/kubernetes.list

# 4. `apt`のパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します:
$ sudo apt-get update
$ sudo apt-get install -y kubelet kubeadm kubectl
$ sudo apt-mark hold kubelet kubeadm kubectl
</code></pre><h4 id=81-kubeletで使用されるcgroupドライバーにsystemdを指定>8.1. kubeletで使用されるcgroupドライバーにsystemdを指定<a hidden class=anchor aria-hidden=true href=#81-kubeletで使用されるcgroupドライバーにsystemdを指定>#</a></h4><pre tabindex=0><code>$ sudo mkdir /var/lib/kubelet
$ echo &#34;KUBELET_EXTRA_ARGS=--cgroup-driver=systemd&#34; | sudo tee /var/lib/kubelet/kubeadm-flags.env
$ sudo systemctl daemon-reload
$ sudo systemctl restart kubelet
</code></pre><h4 id=82-k8sクラスタ作成-コントロールプレーンノードでのみ>8.2. k8sクラスタ作成 (コントロールプレーンノードでのみ)<a hidden class=anchor aria-hidden=true href=#82-k8sクラスタ作成-コントロールプレーンノードでのみ>#</a></h4><pre tabindex=0><code>$ sudo kubeadm init --pod-network-cidr=10.244.0.0/16 --control-plane-endpoint=rp1 --apiserver-cert-extra-sans=rp1
[init] Using Kubernetes version: v1.29.3
[preflight] Running pre-flight checks
   [WARNING SystemVerification]: missing optional cgroups: hugetlb
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;
W0318 00:26:16.828739    1050 checks.go:835] detected that the sandbox image &#34;registry.k8s.io/pause:3.8&#34; of the container runtime is inconsistent with that used by kubeadm. It is recommended that using &#34;registry.k8s.io/pause:3.9&#34; as the CRI sandbox image.
[certs] Using certificateDir folder &#34;/etc/kubernetes/pki&#34;
[certs] Generating &#34;ca&#34; certificate and key
[certs] Generating &#34;apiserver&#34; certificate and key
[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local rp1] and IPs [10.96.0.1 192.168.8.101]
[certs] Generating &#34;apiserver-kubelet-client&#34; certificate and key
[certs] Generating &#34;front-proxy-ca&#34; certificate and key
[certs] Generating &#34;front-proxy-client&#34; certificate and key
[certs] Generating &#34;etcd/ca&#34; certificate and key
[certs] Generating &#34;etcd/server&#34; certificate and key
[certs] etcd/server serving cert is signed for DNS names [localhost rp1] and IPs [192.168.8.101 127.0.0.1 ::1]
[certs] Generating &#34;etcd/peer&#34; certificate and key
[certs] etcd/peer serving cert is signed for DNS names [localhost rp1] and IPs [192.168.8.101 127.0.0.1 ::1]
[certs] Generating &#34;etcd/healthcheck-client&#34; certificate and key
[certs] Generating &#34;apiserver-etcd-client&#34; certificate and key
[certs] Generating &#34;sa&#34; key and public key
[kubeconfig] Writing &#34;admin.conf&#34; kubeconfig fileetes&#34;
[kubeconfig] Writing &#34;super-admin.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;kubelet.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;controller-manager.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;scheduler.conf&#34; kubeconfig file
[etcd] Creating static Pod manifest for local etcd in &#34;/etc/kubernetes/manifests&#34;
[control-plane] Using manifest folder &#34;/etc/kubernetes/manifests&#34;
[control-plane] Creating static Pod manifest for &#34;kube-apiserver&#34;
[control-plane] Creating static Pod manifest for &#34;kube-controller-manager&#34;
[control-plane] Creating static Pod manifest for &#34;kube-scheduler&#34;
[kubelet-start] Writing kubelet environment file with flags to file &#34;/var/lib/kubelet/kubeadm-flags.env&#34;
[kubelet-start] Writing kubelet configuration to file &#34;/var/lib/kubelet/config.yaml&#34;
[kubelet-start] Starting the kubelet
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &#34;/etc/kubernetes/manifests&#34;. This can take up to 4m0s
[apiclient] All control plane components are healthy after 14.505609 seconds
[upload-config] Storing the configuration used in ConfigMap &#34;kubeadm-config&#34; in the &#34;kube-system&#34; Namespace
[kubelet] Creating a ConfigMap &#34;kubelet-config&#34; in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node rp1 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
[mark-control-plane] Marking the node rp1 as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]
[bootstrap-token] Using token: n3np0b.isp8nf8rjz4cyfqt
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the &#34;cluster-info&#34; ConfigMap in the &#34;kube-public&#34; namespace
[kubelet-finalize] Updating &#34;/etc/kubernetes/kubelet.conf&#34; to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &#34;kubectl apply -f [podnetwork].yaml&#34; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of control-plane nodes by copying certificate authorities
and service account keys on each node and then running the following as root:

  kubeadm join rp1:6443 --token n3np0b.isp8nf8rjz4cyfqt \
   --discovery-token-ca-cert-hash sha256:&lt;hash&gt; \
   --control-plane

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join rp1:6443 --token n3np0b.isp8nf8rjz4cyfqt \
   --discovery-token-ca-cert-hash sha256:&lt;hash&gt;
</code></pre><h4 id=83-k8sクラスタへの参加>8.3. k8sクラスタへの参加<a hidden class=anchor aria-hidden=true href=#83-k8sクラスタへの参加>#</a></h4><p>コントロールプレーンに参加するコマンドとワーカーノードに参加するコマンドが表示されます。<br>残り3台はワーカーノードに参加させたいので、後ろのコマンドを3台に実施します。</p><pre tabindex=0><code>$ kubeadm join &lt;control-plane-host&gt;:&lt;control-plane-port&gt; \
    --token &lt;token&gt; \
    --discovery-token-ca-cert-hash sha256:&lt;hash&gt;
</code></pre><blockquote><p>もし、上記joinコマンドを忘れてしまった場合、下記で確認出来ます。<br><code>kubeadm token create --print-join-command</code></p></blockquote><h4 id=84-kubectlを通常ユーザで使えるように>8.4. kubectlを通常ユーザで使えるように<a hidden class=anchor aria-hidden=true href=#84-kubectlを通常ユーザで使えるように>#</a></h4><p>通常ユーザでもkubectlを実行できる様に <code>kubeadm init</code> の結果に表示されているコマンドを実行します。</p><pre tabindex=0><code>$ mkdir -p $HOME/.kube
$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre><h3 id=9-pod間通信用のネットワークアドオン-flannel-インストール>9. pod間通信用のネットワークアドオン <code>flannel</code> インストール<a hidden class=anchor aria-hidden=true href=#9-pod間通信用のネットワークアドオン-flannel-インストール>#</a></h3><p><a href=https://github.com/flannel-io/flannel#deploying-flannel-with-kubectl>こちらの手順</a>を実施する。</p><pre tabindex=0><code>$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
</code></pre><h3 id=10-動作確認>10. 動作確認<a hidden class=anchor aria-hidden=true href=#10-動作確認>#</a></h3><p>上記を実行後にしばらくして、ワーカーノードが <code>Ready</code> になっていればOK。</p><pre tabindex=0><code>$ kubectl get nodes
NAME   STATUS   ROLES           AGE   VERSION
rp1   Ready    control-plane   23h   v1.27.4
rp2   Ready    &lt;none&gt;          22h   v1.27.4
rp3   Ready    &lt;none&gt;          23h   v1.27.4
rp4   Ready    &lt;none&gt;          23h   v1.27.4
</code></pre><p>おわり。<br>そこそこ面倒だったので、Nixで一発で入れられるようにしたいです。<br>(<a href=https://nixos.wiki/wiki/Kubernetes>ここ</a>にほぼ書いてありそうだけど、k8sのお勉強の方を優先しなきゃ&mldr;)</p><h3 id=おまけ>おまけ<a hidden class=anchor aria-hidden=true href=#おまけ>#</a></h3><p><a href=https://4nm1tsu.com/posts/xo2e2qs/#%e7%9c%81%e9%9b%bb%e5%8a%9b%e8%a8%ad%e5%ae%9awi-fibluetooth%e7%84%a1%e5%8a%b9%e5%8c%96>Wi-FIとBluetooth無効化</a>
<code>/etc/modprobe.d/blacklist-8192cu.conf</code>というファイルしかなくて、このファイルをリンク先のように編集したら無効になった。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://lunarxlark.github.io/tags/kubernetes/>Kubernetes</a></li><li><a href=https://lunarxlark.github.io/tags/raspberry-pi/>Raspberry-Pi</a></li></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Raspberry Pi 4 Model B でKubernetes cluster構築した on x" href="https://x.com/intent/tweet/?text=Raspberry%20Pi%204%20Model%20B%20%e3%81%a7Kubernetes%20cluster%e6%a7%8b%e7%af%89%e3%81%97%e3%81%9f&amp;url=https%3a%2f%2flunarxlark.github.io%2farticles%2f20230807_raspi_k8s_cluster%2f&amp;hashtags=kubernetes%2craspberry-pi"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Raspberry Pi 4 Model B でKubernetes cluster構築した on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flunarxlark.github.io%2farticles%2f20230807_raspi_k8s_cluster%2f&amp;title=Raspberry%20Pi%204%20Model%20B%20%e3%81%a7Kubernetes%20cluster%e6%a7%8b%e7%af%89%e3%81%97%e3%81%9f&amp;summary=Raspberry%20Pi%204%20Model%20B%20%e3%81%a7Kubernetes%20cluster%e6%a7%8b%e7%af%89%e3%81%97%e3%81%9f&amp;source=https%3a%2f%2flunarxlark.github.io%2farticles%2f20230807_raspi_k8s_cluster%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Raspberry Pi 4 Model B でKubernetes cluster構築した on reddit" href="https://reddit.com/submit?url=https%3a%2f%2flunarxlark.github.io%2farticles%2f20230807_raspi_k8s_cluster%2f&title=Raspberry%20Pi%204%20Model%20B%20%e3%81%a7Kubernetes%20cluster%e6%a7%8b%e7%af%89%e3%81%97%e3%81%9f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Raspberry Pi 4 Model B でKubernetes cluster構築した on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flunarxlark.github.io%2farticles%2f20230807_raspi_k8s_cluster%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Raspberry Pi 4 Model B でKubernetes cluster構築した on whatsapp" href="https://api.whatsapp.com/send?text=Raspberry%20Pi%204%20Model%20B%20%e3%81%a7Kubernetes%20cluster%e6%a7%8b%e7%af%89%e3%81%97%e3%81%9f%20-%20https%3a%2f%2flunarxlark.github.io%2farticles%2f20230807_raspi_k8s_cluster%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Raspberry Pi 4 Model B でKubernetes cluster構築した on telegram" href="https://telegram.me/share/url?text=Raspberry%20Pi%204%20Model%20B%20%e3%81%a7Kubernetes%20cluster%e6%a7%8b%e7%af%89%e3%81%97%e3%81%9f&amp;url=https%3a%2f%2flunarxlark.github.io%2farticles%2f20230807_raspi_k8s_cluster%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Raspberry Pi 4 Model B でKubernetes cluster構築した on ycombinator" href="https://news.ycombinator.com/submitlink?t=Raspberry%20Pi%204%20Model%20B%20%e3%81%a7Kubernetes%20cluster%e6%a7%8b%e7%af%89%e3%81%97%e3%81%9f&u=https%3a%2f%2flunarxlark.github.io%2farticles%2f20230807_raspi_k8s_cluster%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://lunarxlark.github.io/>/home/lunarxlark/.config/blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>